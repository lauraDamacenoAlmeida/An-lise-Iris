{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regressão Logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### É um algoritmo de classificação  para variaveis categóricas (0 e 1).\n",
    "#### Com ele não só preveremos qual a classe de cada valor, mas também mediremos a probabilidade de um caso pertencer a uma classe especifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/iris.data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length  sepal width  petal length  petal width        class\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.asarray(df[['sepal length','sepal width','petal length','petal width']])\n",
    "y = np.asarray(df[['class']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tratamento do Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = 0\n",
    "for i in y:\n",
    "    if (i == 'Iris-setosa'):\n",
    "        y[pos] = '0'\n",
    "    if(i == 'Iris-virginica'):\n",
    "        y[pos]= '1'\n",
    "    if(i == 'Iris-versicolor'):\n",
    "        y[pos]= '2'\n",
    "    pos+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['0'],\n",
       "       ['0'],\n",
       "       ['0'],\n",
       "       ['0'],\n",
       "       ['0']], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normaliza o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.90068117,  1.03205722, -1.3412724 , -1.31297673],\n",
       "       [-1.14301691, -0.1249576 , -1.3412724 , -1.31297673],\n",
       "       [-1.38535265,  0.33784833, -1.39813811, -1.31297673],\n",
       "       [-1.50652052,  0.10644536, -1.2844067 , -1.31297673],\n",
       "       [-1.02184904,  1.26346019, -1.3412724 , -1.31297673]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "x=preprocessing.StandardScaler().fit(x).transform(x.astype(float))\n",
    "x[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão de treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set de Treino: (120, 4) (120, 1)\n",
      "Set de Teste: (30, 4) (30, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( x, y, test_size=0.2, random_state=4)\n",
    "print ('Set de Treino:', X_train.shape,  y_train.shape)\n",
    "print ('Set de Teste:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Regularização: é uma técnica usada para resolver o problema de overfitting\n",
    "##### O parâmetro C indica: inverse da força de regularização que deve ser um float positivo. Valores menores especificam uma regularização mais forte\n",
    "#### solver = 'liblinear' é recomendado para datasets pequenos. Enquanto 'sag' e 'saga' são mais rápidos para os grandes. \n",
    "####           para problemas multiclasse 'newton-cg', 'sag', 'saga' e 'lbfgs' lidam com a perda multinomial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LauraDamacenodeAlmei\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\LauraDamacenodeAlmei\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='sag',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "LR = LogisticRegression(C=0.01, solver='sag').fit(X_train,y_train)\n",
    "LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1', '0', '1', '1', '1', '2', '2', '0', '0', '2', '0', '0', '0',\n",
       "       '2', '2', '0', '2', '0', '0', '1', '0', '1', '2', '0', '0', '0',\n",
       "       '2', '0', '0', '2'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = LR.predict(X_test)\n",
    "yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### .predict_proba(): retorna estimativas para todas as classes, ordenadas pelo rótulos. [x,y,z]\n",
    "#### A primeira coluna é a probabilidade de ser da classe X. A segunda coluna da classe Y e a terceira coluna é da classe Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12766374, 0.4676096 , 0.40472666],\n",
       "       [0.51942736, 0.19793283, 0.28263982],\n",
       "       [0.09698772, 0.505873  , 0.39713928],\n",
       "       [0.08631604, 0.53994896, 0.37373499],\n",
       "       [0.1050133 , 0.5034359 , 0.3915508 ],\n",
       "       [0.21332158, 0.38033264, 0.40634578],\n",
       "       [0.17360404, 0.4005481 , 0.42584786],\n",
       "       [0.55917592, 0.18317535, 0.25764873],\n",
       "       [0.53852828, 0.19095933, 0.27051238],\n",
       "       [0.17460478, 0.40960625, 0.41578897],\n",
       "       [0.47678674, 0.16469485, 0.3585184 ],\n",
       "       [0.53151659, 0.15619974, 0.31228367],\n",
       "       [0.50014591, 0.14815094, 0.35170314],\n",
       "       [0.20919375, 0.383266  , 0.40754026],\n",
       "       [0.15128477, 0.40828509, 0.44043014],\n",
       "       [0.50331418, 0.15334961, 0.34333621],\n",
       "       [0.24282692, 0.25914876, 0.49802433],\n",
       "       [0.52376133, 0.14742703, 0.32881164],\n",
       "       [0.52196948, 0.16227834, 0.31575217],\n",
       "       [0.15549053, 0.42398001, 0.42052946],\n",
       "       [0.51246184, 0.15601551, 0.33152264],\n",
       "       [0.14673487, 0.49574666, 0.35751846],\n",
       "       [0.14969059, 0.378097  , 0.47221241],\n",
       "       [0.5078556 , 0.17487556, 0.31726884],\n",
       "       [0.51430887, 0.15323571, 0.33245543],\n",
       "       [0.55632437, 0.16916171, 0.27451392],\n",
       "       [0.42454036, 0.14726139, 0.42819825],\n",
       "       [0.55160777, 0.18183283, 0.2665594 ],\n",
       "       [0.49819571, 0.18116467, 0.32063962],\n",
       "       [0.1646845 , 0.41255725, 0.42275825]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_prob = LR.predict_proba(X_test)\n",
    "yhat_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indice de Jaccard\n",
    "##### Podemos definir jaccard como o tamanho da interseção dividida pelo tamanho da união de dois conjuntos de rótulos.\n",
    "##### Se todo o conjunto de rótulos previstos para uma amostra corresponder estritamente ao conjunto real de rótulos, a precisão do subconjunto será 1.0; caso contrário, é 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8666666666666667"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import jaccard_similarity_score\n",
    "jaccard_similarity_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão em porcentagem do teste:  86.66666666666667\n",
      "F1 score:  [0.96774194 0.8        0.71428571]\n"
     ]
    }
   ],
   "source": [
    "print(\"Precisão em porcentagem do teste: \", metrics.accuracy_score(y_test, yhat)*100)\n",
    "print('F1 score: ',metrics.f1_score(y_test, yhat,average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
